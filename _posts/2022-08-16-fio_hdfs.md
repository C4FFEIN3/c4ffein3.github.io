---
layout: post
title: "FIO를 이용한 HDFS의 file I/O 성능 측정"
subtitle: ""
categories: hadoop-ecosystem
tags: [linux, ubuntu, hadoop-ecosystem, fileIO, fio]
---

## FIO

[FIO를 이용한 file I/O 성능 측정](https://c4ffein3.github.io/linux-kernel/2022/08/16/fio.html)

## HDFS

[single-node HDFS 설치 및 실행](https://c4ffein3.github.io/hadoop-ecosystem/2022/07/28/hdfs.html)

[multi-node HDFS 설치 및 실행](https://c4ffein3.github.io/hadoop-ecosystem/2022/08/09/multinodeHDFS.html)

## HDFS 환경

아래 게시글의 멀티노드 HDFS 클러스터 환경을 전제로 한다.

[multi-node HDFS 설치 및 실행](https://c4ffein3.github.io/hadoop-ecosystem/2022/08/09/multinodeHDFS.html)

![https://user-images.githubusercontent.com/57282971/183603076-6fdfa7e0-5388-4db3-b1cb-c8be5b7cc1eb.png](https://user-images.githubusercontent.com/57282971/183603076-6fdfa7e0-5388-4db3-b1cb-c8be5b7cc1eb.png)

해당 게시글은 namenode에서 fio 실험을 하였기 때문에 로컬에 추가적인 HDFS 설치를 하지 않았으나, 별도의 컴퓨터에서 원격으로 fio를 실험하고자 하는 경우 로컬에 HDFS 설치가 필요하다. (fio 빌드 과정에서 HDFS library를 사용하므로)

## HDFS 실험을 위한 FIO 설치

HDFS를 상대로 file I/O를 진행하는 것은 fio 기본 컴파일 옵션에 포함되어있지 않다. 그러므로 apt를 통해 fio를 설치하는 경우, HDFS 실험에는 사용할 수 없다.

### FIO 소스코드 다운로드

- **아래의 링크에서 fio 다운로드**

[https://github.com/axboe/fio/releases](https://github.com/axboe/fio/releases)

- **압축 해제**

```bash
#tar -xzf {다운로드 받은 fio 파일 이름}
tar -xzf fio-3.30.tar.gz
```

- **libhdfs path 설정**

**FIO_LIBHDFS_INCLUDE**, **FIO_LIBHDFS_LIB**의 path를 설정해주어야 한다.

설정하지 않을시 configure를 실행하는 순간 다음과 같은 에러 메세지를 볼 수 있다.

![Untitled](https://user-images.githubusercontent.com/57282971/184828434-01b0df51-c364-4acf-9309-069088c863bc.png)

~/.bashrc에 path를 설정해준다.

path는 hdfs 디렉토리 내의 include와 library path를 설정

```bash
vi ~/.bashrc
```

```bash
#~/.bashrc 아래에 path 추가
#export FIO_LIBHDFS_INCLUDE={HDFS 디렉토리 경로}/include
#export FIO_LIBHDFS_LIB={HDFS 디렉토리 경로}/lib/native
export FIO_LIBHDFS_INCLUDE=/home/hadoop/hadoop-3.2.3/include
export FIO_LIBHDFS_LIB=/home/hadoop/hadoop-3.2.3/lib/native
```

```bash
source ~/.bashrc
```

- **configuration 적용**

 `--enable-libf2fs` 옵션을 추가하여 HDFS 기능을 포함하도록 한다.

```bash
./configure --enable-libhdfs
```

- 컴파일 및 설치

```bash
make
make install
```

## HDFS 실험을 위한 FIO options

다른 I/O engine을 사용할 때와 대부분의 옵션을 동일하게 사용하지만, 몇 가지 옵션을 추가적으로 설정해줘야할 필요가 있다.

### ioengine=libhdfs

HDFS 실험을 할 경우 I/O engine은 libhdfs로 설정

### namenode

HDFS 클러스터의 네임노드의 IP를 설정

### port

HDFS 클러스터의 파일 시스템에 접근하기 위한 포트 설정

HDFS 설정시 fs.defaultFS에서 설정했던 포트를 입력한다.

### hdfsdirectory

HDFS 내부에서 I/O 실험을 실행할 디렉토리 설정

HDFS의 root 디렉토리의 경우 기본적으로 일반 유저의 접근 권한이 없으므로 이를 유의하여야 한다.

### 예시

```
[global]
ioengine=libhdfs
namenode=10.100.54.177
port=9000
hdfsdirectory=/fio
chunk_size=128M

[job]
size=10G
blocksize=128M
rw=write
numjobs=1
```
